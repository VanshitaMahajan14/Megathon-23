{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8dbfffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader, GPTListIndex, GPTVectorStoreIndex, LLMPredictor, PromptHelper, ServiceContext, StorageContext, load_index_from_storage, Document\n",
    "from langchain import OpenAI\n",
    "import gradio as gr\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "199a0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7151feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = '/Users/ashnadua/Desktop/Megathon/data'\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccd19556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full 'all_data' exported to '/Users/ashnadua/Desktop/Megathon/docs/all_data.json' in JSON format.\n"
     ]
    }
   ],
   "source": [
    "output_json_file = '/Users/ashnadua/Desktop/Megathon/docs/all_data.json'\n",
    "\n",
    "with open(output_json_file, 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(all_data, jsonfile, indent=4)\n",
    "\n",
    "print(f\"Full 'all_data' exported to '{output_json_file}' in JSON format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271ca8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50857b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e6556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "33b65312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def construct_index(directory_path):\n",
    "    max_input_size = 4096\n",
    "    num_outputs = 512\n",
    "    max_chunk_overlap = 0.2\n",
    "    chunk_size_limit = 600\n",
    "\n",
    "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
    "\n",
    "    # Pass the API key directly to OpenAI constructor\n",
    "    openai_api_key = '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'\n",
    "    llm_predictor = LLMPredictor(llm=OpenAI(api_key=openai_api_key, temperature=0.7, model_name=\"text-davinci-003\", max_tokens=num_outputs))\n",
    "\n",
    "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
    "    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n",
    "\n",
    "    index = GPTVectorStoreIndex.from_documents(documents)\n",
    "    index.storage_context.persist(persist_dir='Store')\n",
    "\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb22f66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/llms/openai.py:222: UserWarning: WARNING! api_key is not default parameter.\n",
      "                    api_key was transferred to model_kwargs.\n",
      "                    Please confirm that api_key is what you intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mconstruct_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/ashnadua/Desktop/Megathon/docs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[63], line 13\u001b[0m, in \u001b[0;36mconstruct_index\u001b[0;34m(directory_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Pass the API key directly to OpenAI constructor\u001b[39;00m\n\u001b[1;32m     12\u001b[0m openai_api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msk-bpIVMWncV7emWRTIQTaXT3BlbkFJRLmLhKSzuadVd7vB1Y6f\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 13\u001b[0m llm_predictor \u001b[38;5;241m=\u001b[39m LLMPredictor(llm\u001b[38;5;241m=\u001b[39m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopenai_api_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-davinci-003\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m documents \u001b[38;5;241m=\u001b[39m SimpleDirectoryReader(directory_path)\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m     16\u001b[0m service_context \u001b[38;5;241m=\u001b[39m ServiceContext\u001b[38;5;241m.\u001b[39mfrom_defaults(llm_predictor\u001b[38;5;241m=\u001b[39mllm_predictor, prompt_helper\u001b[38;5;241m=\u001b[39mprompt_helper)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/load/serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "index = construct_index(\"/Users/ashnadua/Desktop/Megathon/docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bacb9ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(input_text):\n",
    "    storage_context = StorageContext.from_defaults(persist_dir='Store')\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    query_engine = index.as_query_engine()\n",
    "    \n",
    "    response = query_engine.query(input_text)\n",
    "    \n",
    "    response_string = str(response)\n",
    "    return response_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40271e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/gradio/inputs.py:30: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "/opt/homebrew/lib/python3.11/site-packages/gradio/inputs.py:30: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "/opt/homebrew/lib/python3.11/site-packages/gradio/outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "Running on public URL: https://4df1f2f31658ee7a76.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4df1f2f31658ee7a76.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/gradio/routes.py\", line 422, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/gradio/blocks.py\", line 1323, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/gradio/blocks.py\", line 1051, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/16/36nvykh51lj8191tr2wrzc300000gn/T/ipykernel_55464/1272328702.py\", line 2, in chatbot\n",
      "    storage_context = StorageContext.from_defaults(persist_dir='Store')\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/llama_index/storage/storage_context.py\", line 75, in from_defaults\n",
      "    docstore = docstore or SimpleDocumentStore.from_persist_dir(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/llama_index/storage/docstore/simple_docstore.py\", line 57, in from_persist_dir\n",
      "    return cls.from_persist_path(persist_path, namespace=namespace, fs=fs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/llama_index/storage/docstore/simple_docstore.py\", line 75, in from_persist_path\n",
      "    simple_kvstore = SimpleKVStore.from_persist_path(persist_path, fs=fs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/llama_index/storage/kvstore/simple_kvstore.py\", line 75, in from_persist_path\n",
      "    with fs.open(persist_path, \"rb\") as f:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/fsspec/spec.py\", line 1199, in open\n",
      "    f = self._open(\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/fsspec/implementations/local.py\", line 183, in _open\n",
      "    return LocalFileOpener(path, mode, fs=self, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/fsspec/implementations/local.py\", line 314, in __init__\n",
      "    self._open()\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/fsspec/implementations/local.py\", line 319, in _open\n",
      "    self.f = open(self.path, mode=self.mode)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/ashnadua/Desktop/Megathon/Store/docstore.json'\n"
     ]
    }
   ],
   "source": [
    "iface = gr.Interface(fn=chatbot,\n",
    "                     inputs=gr.inputs.Textbox(lines=7, label=\"Enter your Query\"),\n",
    "                     outputs=gr.outputs.Textbox(label=\"Response\"),\n",
    "                     title=\"Medical GPT\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c54e201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ba436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435492e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb418c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f7f5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14174b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acad259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5767b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac2402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9109c64d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
